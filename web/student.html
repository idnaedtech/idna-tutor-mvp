<!DOCTYPE html>
<html lang="hi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Didi â€” Study Session</title>
    <link href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;600;700;800&display=swap" rel="stylesheet">
    <!-- VAD: ONNX Runtime + Silero VAD (v0.0.22 stable) -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/bundle.min.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }

        :root {
            --warm-bg: #FAF5F0;
            --primary: #FF6B35;
            --primary-light: #FFF0E8;
            --didi-bubble: #FFFFFF;
            --student-bubble: #FF6B35;
            --text: #2D2D2D;
            --text-light: #8A8A8A;
            --border: #EDE5DC;
        }

        html, body {
            height: 100%;
            overflow: hidden;
        }

        body {
            font-family: 'Nunito', sans-serif;
            background: var(--warm-bg);
            color: var(--text);
            display: flex;
            flex-direction: column;
            height: 100dvh;
        }

        /* â”€â”€â”€ Header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
        .header {
            display: flex;
            align-items: center;
            padding: 12px 16px;
            background: white;
            border-bottom: 1px solid var(--border);
            gap: 12px;
            flex-shrink: 0;
        }

        .header-avatar {
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: linear-gradient(135deg, #FF6B35, #FFA726);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 20px;
            flex-shrink: 0;
        }

        .header-info {
            flex: 1;
        }

        .header-name {
            font-size: 16px;
            font-weight: 800;
        }

        .header-status {
            font-size: 12px;
            color: var(--text-light);
            display: flex;
            align-items: center;
            gap: 4px;
        }

        .status-dot-header {
            width: 7px;
            height: 7px;
            border-radius: 50%;
            background: #38A169;
        }

        .header-end-btn {
            padding: 8px 14px;
            border-radius: 10px;
            border: 1.5px solid var(--border);
            background: transparent;
            font-family: 'Nunito', sans-serif;
            font-size: 13px;
            font-weight: 700;
            color: var(--text-light);
            cursor: pointer;
        }

        /* â”€â”€â”€ Chat Area â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
        .chat-area {
            flex: 1;
            overflow-y: auto;
            padding: 16px;
            display: flex;
            flex-direction: column;
            gap: 8px;
            scroll-behavior: smooth;
        }

        .chat-area::-webkit-scrollbar { width: 4px; }
        .chat-area::-webkit-scrollbar-thumb { background: #D0C8C0; border-radius: 4px; }

        /* Bubbles */
        .msg {
            max-width: 82%;
            padding: 12px 16px;
            border-radius: 18px;
            font-size: 15px;
            line-height: 1.5;
            animation: msgIn 0.25s ease-out;
            position: relative;
        }

        @keyframes msgIn {
            from { opacity: 0; transform: translateY(8px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .msg.didi {
            align-self: flex-start;
            background: var(--didi-bubble);
            border-bottom-left-radius: 6px;
            box-shadow: 0 1px 4px rgba(0,0,0,0.04);
        }

        .msg.student {
            align-self: flex-end;
            background: var(--student-bubble);
            color: white;
            border-bottom-right-radius: 6px;
        }

        .msg .play-btn {
            display: inline-flex;
            align-items: center;
            gap: 5px;
            margin-top: 6px;
            padding: 4px 10px;
            border-radius: 12px;
            background: var(--primary-light);
            border: none;
            font-family: 'Nunito', sans-serif;
            font-size: 12px;
            font-weight: 700;
            color: var(--primary);
            cursor: pointer;
        }

        .msg.student .play-btn {
            background: rgba(255,255,255,0.2);
            color: white;
        }

        .msg .timestamp {
            font-size: 11px;
            color: var(--text-light);
            margin-top: 4px;
        }
        .msg.student .timestamp { color: rgba(255,255,255,0.7); }

        /* Typing indicator */
        .typing {
            align-self: flex-start;
            padding: 14px 20px;
            background: var(--didi-bubble);
            border-radius: 18px;
            border-bottom-left-radius: 6px;
            box-shadow: 0 1px 4px rgba(0,0,0,0.04);
            display: none;
        }

        .typing.show { display: flex; gap: 5px; }

        .typing-dot {
            width: 8px;
            height: 8px;
            background: #C0B8B0;
            border-radius: 50%;
            animation: typingBounce 1.2s ease-in-out infinite;
        }
        .typing-dot:nth-child(2) { animation-delay: 0.15s; }
        .typing-dot:nth-child(3) { animation-delay: 0.3s; }

        @keyframes typingBounce {
            0%, 60%, 100% { transform: translateY(0); }
            30% { transform: translateY(-6px); }
        }

        /* â”€â”€â”€ Voice Status Area (replaces mic button) â”€â”€â”€ */
        .voice-area {
            padding: 16px;
            background: white;
            border-top: 1px solid var(--border);
            text-align: center;
            flex-shrink: 0;
        }

        .voice-indicator {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 8px;
        }

        .status-dot {
            width: 24px;
            height: 24px;
            border-radius: 50%;
            transition: all 0.3s ease;
        }

        .status-dot.green { background: #4CAF50; }
        .status-dot.green.pulse { animation: pulse 2s ease-in-out infinite; }
        .status-dot.green.bright { background: #66BB6A; box-shadow: 0 0 16px #4CAF50; }
        .status-dot.yellow { background: #FFC107; }
        .status-dot.blue { background: #2196F3; }
        .status-dot.red { background: #F44336; }

        @keyframes pulse {
            0%, 100% { opacity: 0.6; transform: scale(1); }
            50% { opacity: 1; transform: scale(1.2); }
        }

        .status-text {
            font-size: 14px;
            color: var(--text-light);
            font-weight: 600;
        }

        /* Fallback mic button (hidden by default) */
        .mic-fallback {
            display: none;
            text-align: center;
        }

        .mic-fallback .mic-btn {
            width: 64px;
            height: 64px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, var(--primary), #FF8A50);
            color: white;
            font-size: 28px;
            cursor: pointer;
            box-shadow: 0 4px 16px rgba(255,107,53,0.25);
        }

        .mic-fallback .mic-btn.recording {
            background: #E53E3E;
            animation: pulse 1s ease-in-out infinite;
        }

        /* Text input (optional - kept for accessibility) */
        .text-input-area {
            display: flex;
            gap: 10px;
            margin-top: 12px;
            padding: 0 16px;
        }

        .text-input {
            flex: 1;
            padding: 10px 14px;
            border-radius: 20px;
            border: 1.5px solid var(--border);
            font-family: 'Nunito', sans-serif;
            font-size: 14px;
            outline: none;
            background: var(--warm-bg);
        }

        .text-input:focus { border-color: var(--primary); }

        .send-btn {
            width: 40px;
            height: 40px;
            border-radius: 50%;
            border: none;
            background: var(--primary);
            color: white;
            font-size: 16px;
            cursor: pointer;
        }

        /* â”€â”€â”€ Session overlay â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
        .overlay {
            position: fixed;
            inset: 0;
            background: rgba(0,0,0,0.3);
            display: none;
            align-items: center;
            justify-content: center;
            z-index: 100;
        }

        .overlay.show { display: flex; }

        .overlay-card {
            background: white;
            border-radius: 20px;
            padding: 28px;
            text-align: center;
            max-width: 320px;
            width: 90%;
            box-shadow: 0 16px 48px rgba(0,0,0,0.15);
        }

        .overlay-card h2 {
            font-size: 20px;
            margin-bottom: 8px;
        }

        .overlay-card p {
            font-size: 14px;
            color: var(--text-light);
            margin-bottom: 20px;
        }

        .overlay-card .stats {
            display: flex;
            gap: 16px;
            justify-content: center;
            margin-bottom: 20px;
        }

        .stat-box {
            text-align: center;
        }

        .stat-box .num {
            font-size: 28px;
            font-weight: 800;
            color: var(--primary);
        }

        .stat-box .label {
            font-size: 12px;
            color: var(--text-light);
        }

        .overlay-btn {
            padding: 14px 32px;
            border: none;
            border-radius: 14px;
            background: var(--primary);
            color: white;
            font-family: 'Nunito', sans-serif;
            font-size: 15px;
            font-weight: 800;
            cursor: pointer;
        }
    </style>
</head>
<body>
    <!-- Header -->
    <div class="header">
        <div class="header-avatar">ğŸ“š</div>
        <div class="header-info">
            <div class="header-name">Didi à¤¦à¥€à¤¦à¥€</div>
            <div class="header-status">
                <span class="status-dot-header"></span>
                <span id="headerStatus">Connecting...</span>
            </div>
        </div>
        <button class="header-end-btn" onclick="endSession()">End</button>
    </div>

    <!-- Chat -->
    <div class="chat-area" id="chatArea">
        <div class="typing" id="typing">
            <div class="typing-dot"></div>
            <div class="typing-dot"></div>
            <div class="typing-dot"></div>
        </div>
    </div>

    <!-- Voice Status (VAD-based, no mic button) -->
    <div class="voice-area">
        <div id="voiceIndicator" class="voice-indicator">
            <div id="voiceStatus" class="status-dot green pulse"></div>
            <p id="statusText" class="status-text">Starting...</p>
        </div>

        <!-- Fallback mic button for browsers without WASM support -->
        <div id="micFallback" class="mic-fallback">
            <button id="micBtn" class="mic-btn" onclick="toggleRecording()">ğŸ¤</button>
            <p style="margin-top: 8px; font-size: 12px; color: #999;">Tap to speak</p>
        </div>

        <!-- Optional text input -->
        <div class="text-input-area">
            <input type="text" class="text-input" id="textInput" placeholder="Ya type karo..."
                   onkeydown="if(event.key==='Enter')sendText()">
            <button class="send-btn" id="sendBtn" onclick="sendText()">â¤</button>
        </div>
    </div>

    <!-- Session end overlay -->
    <div class="overlay" id="endOverlay">
        <div class="overlay-card">
            <h2>Aaj ki padhai ho gayi! ğŸ‰</h2>
            <p id="summaryText"></p>
            <div class="stats">
                <div class="stat-box">
                    <div class="num" id="statCorrect">0</div>
                    <div class="label">Sahi</div>
                </div>
                <div class="stat-box">
                    <div class="num" id="statTotal">0</div>
                    <div class="label">Total</div>
                </div>
            </div>
            <button class="overlay-btn" onclick="window.location.href='/'">Bye Didi! ğŸ‘‹</button>
        </div>
    </div>

    <script>
    // ============================================================
    // IDNA v7.1.0 â€” VAD Auto-Recording + Silence Fix
    // ============================================================

    const API = window.location.origin;
    const token = localStorage.getItem('idna_token');
    const studentName = localStorage.getItem('idna_name') || 'Student';

    if (!token) window.location.href = '/';

    // â”€â”€â”€ State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    let sessionId = null;
    let vadInstance = null;
    let isProcessing = false;   // True while pipeline is running
    let isDidiSpeaking = false; // True while TTS audio is playing
    let currentAudio = null;

    // Silence timer (Part C fix)
    let inactivityTimer = null;
    const INACTIVITY_TIMEOUT = 30000; // 30 seconds (was 15s)

    // Fallback recording state
    let isRecording = false;
    let mediaRecorder = null;
    let audioChunks = [];
    let audioCache = {};  // Store audio by message ID
    let messageCounter = 0;

    // DOM refs
    const chatArea = document.getElementById('chatArea');
    const typing = document.getElementById('typing');
    const voiceStatus = document.getElementById('voiceStatus');
    const statusText = document.getElementById('statusText');
    const headerStatus = document.getElementById('headerStatus');
    const textInput = document.getElementById('textInput');

    // â”€â”€â”€ VAD Initialization â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async function initVAD() {
        try {
            vadInstance = await vad.MicVAD.new({
                // When student starts speaking
                onSpeechStart: () => {
                    if (isDidiSpeaking || isProcessing) return;
                    updateVoiceUI('listening');
                    clearInactivityTimer(); // Reset silence timer on speech
                    console.log("[VAD] Speech detected â€” recording...");
                },

                // When student stops speaking (silence detected)
                onSpeechEnd: async (audioFloat32) => {
                    if (isDidiSpeaking || isProcessing) return;

                    isProcessing = true;
                    updateVoiceUI('processing');
                    console.log("[VAD] Speech ended â€” sending to pipeline...");

                    try {
                        // Convert Float32Array (16kHz) to WAV blob for STT
                        const wavBlob = float32ToWav(audioFloat32, 16000);
                        await sendAudioToPipeline(wavBlob);
                    } catch (err) {
                        console.error("[VAD] Pipeline error:", err);
                        updateVoiceUI('error');
                        setTimeout(() => updateVoiceUI('ready'), 2000);
                    } finally {
                        isProcessing = false;
                    }
                },

                // VAD tuning for Indian classroom environments
                positiveSpeechThreshold: 0.6,
                negativeSpeechThreshold: 0.35,
                redemptionFrames: 12,  // ~750ms silence before cutting off
                minSpeechFrames: 5,    // Minimum speech to avoid clicks

                // CDN paths for ONNX model files (v0.0.22 has stable model)
                workletURL: "https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/vad.worklet.bundle.min.js",
                modelURL: "https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/silero_vad.onnx",
                ortConfig: (ort) => {
                    ort.env.wasm.wasmPaths = "https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/";
                },
            });

            console.log("[VAD] Initialized successfully");
            return true;

        } catch (err) {
            console.error("[VAD] Init failed:", err);
            return false;
        }
    }

    // Start VAD listening
    function startListening() {
        if (vadInstance && !isDidiSpeaking && !isProcessing) {
            vadInstance.start();
            updateVoiceUI('ready');
            startInactivityTimer(); // Start silence timer when ready for input
        }
    }

    // Pause VAD (when Didi is speaking)
    function pauseListening() {
        if (vadInstance) {
            vadInstance.pause();
        }
        clearInactivityTimer(); // Don't count silence while Didi speaks
    }

    // Convert Float32Array to WAV blob
    function float32ToWav(float32Array, sampleRate) {
        const buffer = new ArrayBuffer(44 + float32Array.length * 2);
        const view = new DataView(buffer);

        const writeString = (offset, str) => {
            for (let i = 0; i < str.length; i++) view.setUint8(offset + i, str.charCodeAt(i));
        };

        writeString(0, 'RIFF');
        view.setUint32(4, 36 + float32Array.length * 2, true);
        writeString(8, 'WAVE');
        writeString(12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);        // PCM
        view.setUint16(22, 1, true);        // Mono
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * 2, true);
        view.setUint16(32, 2, true);
        view.setUint16(34, 16, true);       // 16-bit
        writeString(36, 'data');
        view.setUint32(40, float32Array.length * 2, true);

        const offset = 44;
        for (let i = 0; i < float32Array.length; i++) {
            const s = Math.max(-1, Math.min(1, float32Array[i]));
            view.setInt16(offset + i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
        }

        return new Blob([buffer], { type: 'audio/wav' });
    }

    // â”€â”€â”€ Voice UI Updates â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    function updateVoiceUI(state) {
        switch (state) {
            case 'ready':
                voiceStatus.className = 'status-dot green pulse';
                statusText.textContent = 'Aapki baari â€” boliye!';
                break;
            case 'listening':
                voiceStatus.className = 'status-dot green bright';
                statusText.textContent = 'Sun rahi hoon...';
                break;
            case 'processing':
                voiceStatus.className = 'status-dot yellow';
                statusText.textContent = 'Didi soch rahi hai...';
                break;
            case 'didi-speaking':
                voiceStatus.className = 'status-dot blue';
                statusText.textContent = 'Didi bol rahi hai...';
                break;
            case 'error':
                voiceStatus.className = 'status-dot red';
                statusText.textContent = 'Phir se boliye?';
                break;
        }
    }

    // Show fallback mic button if VAD fails
    function showManualMicButton() {
        document.getElementById('voiceIndicator').style.display = 'none';
        document.getElementById('micFallback').style.display = 'block';
    }

    // â”€â”€â”€ Inactivity Timer (Part C fix) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    function startInactivityTimer() {
        clearInactivityTimer();
        inactivityTimer = setTimeout(() => {
            // Only trigger if not speaking and not processing
            if (!isDidiSpeaking && !isProcessing && sessionId) {
                console.log("[Silence] 30s inactivity â€” sending nudge");
                sendSilenceNudge();
            }
        }, INACTIVITY_TIMEOUT);
    }

    function clearInactivityTimer() {
        if (inactivityTimer) {
            clearTimeout(inactivityTimer);
            inactivityTimer = null;
        }
    }

    async function sendSilenceNudge() {
        const formData = new FormData();
        formData.append('session_id', sessionId);
        formData.append('text', '[silence]');

        try {
            const resp = await fetch(`${API}/api/student/session/message`, {
                method: 'POST',
                headers: { 'Authorization': `Bearer ${token}` },
                body: formData,
            });

            if (resp.ok) {
                const data = await resp.json();
                addMessage('didi', data.didi_text, data.didi_audio_b64);
                if (data.didi_audio_b64) {
                    await playDidiAudio(data.didi_audio_b64);
                }
            }
        } catch (e) {
            console.error("[Silence] Nudge failed:", e);
        }

        // Restart timer after nudge
        startInactivityTimer();
    }

    // â”€â”€â”€ Audio Playback â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async function playDidiAudio(b64) {
        console.log("[Audio] playDidiAudio called, b64 length:", b64 ? b64.length : 0);

        if (!b64 || b64.length === 0) {
            console.error("[Audio] No audio data provided");
            startListening();
            return;
        }

        isDidiSpeaking = true;
        pauseListening();
        updateVoiceUI('didi-speaking');

        return new Promise((resolve) => {
            try {
                console.log("[Audio] Decoding base64...");
                const bytes = atob(b64);
                const arr = new Uint8Array(bytes.length);
                for (let i = 0; i < bytes.length; i++) arr[i] = bytes.charCodeAt(i);

                console.log("[Audio] Creating blob, size:", arr.length, "bytes");
                const blob = new Blob([arr], { type: 'audio/mp3' });
                const url = URL.createObjectURL(blob);
                console.log("[Audio] Blob URL created:", url);

                if (currentAudio) {
                    currentAudio.pause();
                    currentAudio = null;
                }

                currentAudio = new Audio(url);
                console.log("[Audio] Audio element created");

                currentAudio.onended = () => {
                    console.log("[Audio] Playback ended successfully");
                    URL.revokeObjectURL(url);
                    isDidiSpeaking = false;
                    currentAudio = null;

                    // Auto-start listening after Didi finishes
                    startListening();
                    resolve();
                };

                currentAudio.onerror = (e) => {
                    console.error("[Audio] Playback error:", e, currentAudio.error);
                    isDidiSpeaking = false;
                    startListening();
                    resolve();
                };

                console.log("[Audio] Calling play()...");
                currentAudio.play().then(() => {
                    console.log("[Audio] Play started successfully");
                }).catch((e) => {
                    console.error("[Audio] Play failed:", e.name, e.message);
                    // Try to show a play button if autoplay blocked
                    if (e.name === 'NotAllowedError') {
                        console.log("[Audio] Autoplay blocked - user interaction required");
                    }
                    isDidiSpeaking = false;
                    startListening();
                    resolve();
                });

            } catch (e) {
                console.error("[Audio] Decode error:", e);
                isDidiSpeaking = false;
                startListening();
                resolve();
            }
        });
    }

    // â”€â”€â”€ Send Audio to Pipeline (Streaming v7.1) â”€â”€â”€â”€â”€â”€â”€â”€
    async function sendAudioToPipeline(wavBlob) {
        if (!sessionId) return;

        // Show student bubble placeholder
        addMessage('student', 'ğŸ¤ ...');
        showTyping(true);

        // Convert blob to base64
        const reader = new FileReader();
        const audioB64 = await new Promise((resolve) => {
            reader.onloadend = () => resolve(reader.result.split(',')[1]);
            reader.readAsDataURL(wavBlob);
        });

        try {
            // v7.1.1: Streaming disabled temporarily - SSE chunk parsing issues
            // TODO: Fix SSE buffering for partial JSON chunks
            // For now, use reliable non-streaming endpoint
            return sendAudioNonStreaming(wavBlob);

            /* DISABLED: Streaming endpoint
            const resp = await fetch(`${API}/api/student/session/message-stream`, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${token}`,
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    session_id: sessionId,
                    audio: audioB64,
                }),
            });

            if (!resp.ok) {
                // Fallback to non-streaming endpoint
                return sendAudioNonStreaming(wavBlob);
            }
            */

            showTyping(false);

            // Process SSE stream
            const eventReader = resp.body.getReader();
            const decoder = new TextDecoder();
            let audioQueue = [];
            let isPlaying = false;
            let fullText = '';
            let transcript = '';
            let verdict = null;
            let newState = null;

            while (true) {
                const { done, value } = await eventReader.read();
                if (done) break;

                const text = decoder.decode(value);
                const lines = text.split('\n').filter(l => l.startsWith('data: '));

                for (const line of lines) {
                    try {
                        const data = JSON.parse(line.substring(6));

                        if (data.type === 'audio_chunk') {
                            const audioBytes = Uint8Array.from(atob(data.audio), c => c.charCodeAt(0));
                            const blob = new Blob([audioBytes], { type: 'audio/mp3' });
                            audioQueue.push({ blob, isLast: data.is_last });

                            // Start playing first chunk immediately
                            if (!isPlaying && audioQueue.length === 1) {
                                isPlaying = true;
                                isDidiSpeaking = true;
                                pauseListening();
                                updateVoiceUI('didi-speaking');
                                playNextChunk();
                            }
                        }

                        if (data.type === 'text') {
                            fullText = data.content;
                        }

                        if (data.type === 'transcript') {
                            transcript = data.content;
                            // Update student bubble
                            const studentMsgs = chatArea.querySelectorAll('.msg.student');
                            const lastStudent = studentMsgs[studentMsgs.length - 1];
                            if (lastStudent && transcript) {
                                lastStudent.querySelector('.text').textContent = transcript;
                            }
                        }

                        if (data.type === 'verdict') {
                            verdict = data.value;
                            // Update student bubble with emoji
                            if (verdict !== null) {
                                const studentMsgs = chatArea.querySelectorAll('.msg.student');
                                const lastStudent = studentMsgs[studentMsgs.length - 1];
                                if (lastStudent) {
                                    const emoji = verdict ? 'âœ…' : 'âŒ';
                                    lastStudent.querySelector('.text').textContent = transcript + ' ' + emoji;
                                }
                            }
                        }

                        if (data.type === 'done') {
                            newState = data.state;
                            // Add Didi's message to chat (without audio - already playing)
                            if (fullText) {
                                addMessage('didi', fullText);
                            }
                            if (newState === 'SESSION_COMPLETE') {
                                setTimeout(() => endSession(), 2000);
                            }
                        }
                    } catch (e) {
                        console.error('[SSE] Parse error:', e);
                    }
                }
            }

            // Play audio chunks sequentially
            function playNextChunk() {
                if (audioQueue.length === 0) {
                    isDidiSpeaking = false;
                    startListening();
                    return;
                }

                const { blob } = audioQueue.shift();
                const url = URL.createObjectURL(blob);
                const audio = new Audio(url);

                audio.onended = () => {
                    URL.revokeObjectURL(url);
                    playNextChunk();
                };

                audio.onerror = () => {
                    URL.revokeObjectURL(url);
                    playNextChunk();
                };

                audio.play().catch(() => playNextChunk());
            }

        } catch (err) {
            console.error('[Stream] Error:', err);
            // Fallback to non-streaming
            return sendAudioNonStreaming(wavBlob);
        }
    }

    // Fallback non-streaming send (for older browsers or if streaming fails)
    async function sendAudioNonStreaming(wavBlob) {
        const formData = new FormData();
        formData.append('session_id', sessionId);
        formData.append('audio', wavBlob, 'recording.wav');

        try {
            const resp = await fetch(`${API}/api/student/session/message`, {
                method: 'POST',
                headers: { 'Authorization': `Bearer ${token}` },
                body: formData,
            });

            showTyping(false);

            if (!resp.ok) throw new Error('Message failed');

            const data = await resp.json();
            logLatency(data);

            const studentMsgs = chatArea.querySelectorAll('.msg.student');
            const lastStudent = studentMsgs[studentMsgs.length - 1];
            if (lastStudent && data.student_transcript) {
                const text = data.verdict
                    ? `${data.student_transcript} ${getVerdictEmoji(data.verdict)}`
                    : data.student_transcript;
                lastStudent.querySelector('.text').textContent = text;
            }

            addMessage('didi', data.didi_text, data.didi_audio_b64);

            if (data.didi_audio_b64) {
                await playDidiAudio(data.didi_audio_b64);
            } else {
                startListening();
            }

            if (data.state === 'SESSION_COMPLETE') {
                setTimeout(() => endSession(), 2000);
            }

        } catch (err) {
            showTyping(false);
            addMessage('didi', 'Kuch gadbad ho gayi. Ek baar phir try karo.');
            updateVoiceUI('error');
            setTimeout(() => startListening(), 2000);
        }
    }

    // â”€â”€â”€ Send Text â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async function sendText() {
        const text = textInput.value.trim();
        if (!text || !sessionId) return;

        textInput.value = '';
        clearInactivityTimer();

        addMessage('student', text);
        showTyping(true);
        updateVoiceUI('processing');

        const formData = new FormData();
        formData.append('session_id', sessionId);
        formData.append('text', text);

        try {
            const resp = await fetch(`${API}/api/student/session/message`, {
                method: 'POST',
                headers: { 'Authorization': `Bearer ${token}` },
                body: formData,
            });

            showTyping(false);

            if (!resp.ok) throw new Error('Message failed');

            const data = await resp.json();
            logLatency(data);

            addMessage('didi', data.didi_text, data.didi_audio_b64);

            if (data.didi_audio_b64) {
                await playDidiAudio(data.didi_audio_b64);
            } else {
                startListening();
            }

            if (data.state === 'SESSION_COMPLETE') {
                setTimeout(() => endSession(), 2000);
            }

        } catch (err) {
            showTyping(false);
            addMessage('didi', 'Connection mein problem. Ek baar phir try karo.');
            startListening();
        }
    }

    // â”€â”€â”€ Fallback Manual Recording â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async function toggleRecording() {
        if (isRecording) {
            stopRecording();
        } else {
            startRecording();
        }
    }

    async function startRecording() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                audio: { echoCancellation: true, noiseSuppression: true }
            });
            mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
            audioChunks = [];

            mediaRecorder.ondataavailable = (e) => {
                if (e.data.size > 0) audioChunks.push(e.data);
            };

            mediaRecorder.onstop = () => {
                stream.getTracks().forEach(t => t.stop());
                const blob = new Blob(audioChunks, { type: 'audio/webm' });
                sendAudioToPipeline(blob);
            };

            mediaRecorder.start();
            isRecording = true;
            document.getElementById('micBtn').classList.add('recording');
            document.getElementById('micBtn').textContent = 'â¹';
            clearInactivityTimer();

        } catch (err) {
            console.error('Mic access denied:', err);
            addMessage('didi', 'Microphone ki permission chahiye.');
        }
    }

    function stopRecording() {
        if (mediaRecorder && mediaRecorder.state === 'recording') {
            mediaRecorder.stop();
        }
        isRecording = false;
        document.getElementById('micBtn').classList.remove('recording');
        document.getElementById('micBtn').textContent = 'ğŸ¤';
    }

    // â”€â”€â”€ Session Start â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async function startSession() {
        headerStatus.textContent = 'Connecting...';
        statusText.textContent = 'Starting...';

        try {
            const resp = await fetch(`${API}/api/student/session/start`, {
                method: 'POST',
                headers: { 'Authorization': `Bearer ${token}` },
            });

            if (!resp.ok) throw new Error('Session start failed');

            const data = await resp.json();
            sessionId = data.session_id;
            headerStatus.textContent = 'Online';

            // Show greeting
            addMessage('didi', data.greeting_text, data.greeting_audio_b64);

            // Play greeting, then start listening
            if (data.greeting_audio_b64) {
                await playDidiAudio(data.greeting_audio_b64);
            } else {
                startListening();
            }

        } catch (err) {
            headerStatus.textContent = 'Connection error';
            statusText.textContent = 'Error';
            addMessage('didi', 'Server se connect nahi ho pa rahi. Thodi der baad try karo.');
        }
    }

    // â”€â”€â”€ End Session â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async function endSession() {
        clearInactivityTimer();
        if (vadInstance) vadInstance.pause();

        if (!sessionId) {
            window.location.href = '/';
            return;
        }

        try {
            const formData = new FormData();
            formData.append('session_id', sessionId);

            const resp = await fetch(`${API}/api/student/session/end`, {
                method: 'POST',
                headers: { 'Authorization': `Bearer ${token}` },
                body: formData,
            });

            if (resp.ok) {
                const data = await resp.json();
                document.getElementById('summaryText').textContent = data.summary_text;
                document.getElementById('statCorrect').textContent = data.questions_correct;
                document.getElementById('statTotal').textContent = data.questions_attempted;

                if (data.summary_audio_b64) {
                    playDidiAudio(data.summary_audio_b64);
                }
            }
        } catch (e) { /* show overlay anyway */ }

        document.getElementById('endOverlay').classList.add('show');
    }

    // â”€â”€â”€ Messages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    function addMessage(who, text, audioB64 = null) {
        const div = document.createElement('div');
        div.className = `msg ${who}`;

        // Store audio in cache, reference by ID (fixes 366KB onclick bug)
        const msgId = ++messageCounter;
        if (audioB64 && who === 'didi') {
            audioCache[msgId] = audioB64;
        }

        let html = `<div class="text">${text}</div>`;

        if (audioB64 && who === 'didi') {
            html += `<button class="play-btn" onclick="playAudioById(${msgId})">
                ğŸ”Š Sunein
            </button>`;
        }

        const now = new Date();
        const time = now.getHours().toString().padStart(2,'0') + ':' +
                     now.getMinutes().toString().padStart(2,'0');
        html += `<div class="timestamp">${time}</div>`;

        div.innerHTML = html;
        chatArea.insertBefore(div, typing);
        scrollToBottom();
    }

    // Play audio from cache by message ID
    function playAudioById(msgId) {
        const b64 = audioCache[msgId];
        if (b64) {
            playDidiAudio(b64);
        }
    }

    function scrollToBottom() {
        chatArea.scrollTop = chatArea.scrollHeight;
    }

    function showTyping(show) {
        typing.classList.toggle('show', show);
        if (show) scrollToBottom();
    }

    // â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    function logLatency(data) {
        if (data.total_ms) {
            console.log(`â±ï¸ Latency: STT=${data.stt_ms}ms LLM=${data.llm_ms}ms TTS=${data.tts_ms}ms Total=${data.total_ms}ms`);
        }
    }

    function getVerdictEmoji(v) {
        if (v === 'CORRECT') return 'âœ…';
        if (v === 'INCORRECT') return 'âŒ';
        return '';
    }

    // â”€â”€â”€ Init â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    window.addEventListener('load', async () => {
        // Request mic permission first
        try {
            await navigator.mediaDevices.getUserMedia({ audio: true });
        } catch (err) {
            alert('Mic permission chahiye. Please allow microphone access.');
            showManualMicButton();
            await startSession();
            return;
        }

        // Try to initialize VAD
        const vadOk = await initVAD();

        if (!vadOk) {
            console.log("[VAD] Falling back to manual mic button");
            showManualMicButton();
        }

        // Start the session
        await startSession();
    });
    </script>
</body>
</html>
